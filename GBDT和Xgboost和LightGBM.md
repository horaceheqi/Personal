AdaBoost
---
原始的Adaboost算法开始的时候，为每一个样本赋上一个权重值，初始的时候，大家都是一样重要。在每一步训练中得到模型，会使得数据点的估计有对错，我们就在每一步结束后，增加分错点的权重，减少分对点的权重，这样使得某些点如果老师被分错，那么就会被"重点关注"，也就被赋一个很高的权重。然后等进行了N次迭代(由用户决定)，将会得到N个简单的分类器(basic learner)，然后我们将它们组合起来(加权、投票等等)得到一个最终模型

GBDT
---
GBDT(Gradient Boosting Decision Tree)中的树都是回归树，GBDT用来做回归预测，调整后也可以用于分类(设定阈值，大于阈值为正例，反之为负例)，可以发现多种有区分性的特征以及特征组合。GBDT是把所有树的结论累加起来做最终结论的，GBDT的核心就在于每一颗树学的是之前所有树结论和的残差(负梯度)，这个残差就是一个加预测值后能得真实值的累加量。比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁，那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二课树真能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在一岁的残差，第三棵树A的年龄就变成了1岁，继续学，Boosting的最大好处在于每一步的残差计算其实变相地增大了分错instance的权重，而已经分对的instance则都趋向于0，这样后面的树就能越来越专注哪些前面被分错的instance。

Xgboost
---
不同的机器学习模型适用于不同类型的任务。深度神经网络通过对时空位置建模，能够很好地捕获图像、语音、文本等高纬度数据。而基于树模型的Xgboost则能够很好地处理表格数据，同时还拥有一些深度神经网络所没有的特性(如：模型的可解释性、输入数据的不变性，更易于调参等)
- Xgboost 专注于模型的可解释性，而基于神经网路的深度学习，则更关注模型的准确度。
- Xgboost 更适用于变量数量较少的表格数据，而深度学习则更适用于图像或其他拥有海量变量的数据。
